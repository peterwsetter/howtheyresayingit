---
title: "Who's Being Talked About?: Identifying and Analyzing Quotes in News Text"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Last Updated: November 11, 2018

## Background

How information is included in an article is a major choice in its writing. In addition to the framing and balance of sources, the journalist must decide when to use a quote and when to paraphrase a source. Direct quotes can be powerful, potentially driving the readers' take-away from an article; however, the sentiment of quotes may be offset by the framing of the writer.

This post will use the `stringr` and `tidytext` packages, amongst others, to identify quotes within news articles and compare the sentiment of quotes compared to the remainder of the article.

I decided to use the [BBC News Summary](https://www.kaggle.com/pariza/bbc-news-summary) dataset from Kaggle. The main advantage of this dataset is its uniform structure.

- Article text is stored in plain text files. No worries about formatting or extraneous material.
- Each articles contains the headline, the lead, and three or four paragraphs.

The first step of the project involved creating two database tables: `articles` and `article_content`. `articles` contains the `article_id`, `topic`, `headline`, and `lead`, and `article_content` included the `paragraph_text` identified by the `article_id` and `paragraph_num`.

```{r}
library(dplyr)
library(DBI)
library(MonetDBLite)

dbdir <- '../../data/bbcdb/'

con <- dbConnect(MonetDBLite::MonetDBLite(), dbdir)

tbl(con, 'articles')
```

```{r}
tbl(con, 'article_content') 
```

## What's Being Written About?

The headlines can be used to identify the important keywords from this time. To simplify the analysis, the focus will be articles from the "Politics" topic.

To identify keywords, I will tokenize the headlines using the `tidytext` package, remove stop words, and perform a straightforward count.

```{r}
library(tidytext)

data(stop_words)

tbl(con, 'articles') %>% 
  # Only interested in the headlines of politics articles.
  filter(topic == 'politics') %>% 
  select(headline) %>% 
  collect() %>% 
  unnest_tokens(
    output = word,
    input = headline,
    token = 'words'
  ) %>% 
  # Remove stop words
  anti_join(stop_words) %>% 
  group_by(word) %>% 
  count() %>% 
  arrange(desc(n)) %>% 
  View()
```

## Identifying Quotes

My strategy for identifying quotes is to extract/replace them using `"` as a marker. The key is a regular expression that can capture the beginning and ending of a quote.

In plain text, the opening `"` will be immediately followed by a alphabetic character. There are two ways of representing this: `"[A-z]` or `"[:alpha:]`. The former uses a character range, while the latter uses a POSIX character class. 

Identifying a closing `"` is slightly more difficult since puncuation may proceed or follow it. Before the `"`, we'll see a alphabetic with zero or one puncutation marks; this is represented in a regular expression as `[:alpha:][:punct:]{0,1}"`. Similarily, an optional punctuation mark after a quote is represented as `[:punct:]{0,1}`. 

The interior text can be represented with a simple wildcard character, wildcard number regular expression: `.*`. Putting it all together, the regular expression is:

`"[:alpha:].*[:alpha:][:punct:]{0,1}"[:punct:]{0,1}`

```{r shutdown}
dbDisconnect(con, shutdown=TRUE)
```